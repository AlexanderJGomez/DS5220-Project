{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file will be used to create an automatic metric for redundancy, which may be used as a feature in the model we plan to create to predict redundancy.  The metric will use the Universal Sentence Encoder found [here](https://www.tensorflow.org/hub/modules/google/universal-sentence-encoder-large/3) to create vector representations of sentences, then we will compute the squared cosine similarities for all pairs of sentences.  Lastly, we compute the mean of the cosine similarities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats.stats import pearsonr, spearmanr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In here we retrieve the post edits from the SQLite DB.  Then, we just retrieve the first instance of a system summary.  this is because we only care about the system summaries, not the post edits, so we can avoid doing extra work by only keeping 1 postedit per each system summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conn = sqlite3.connect(\"../data/cdm_postedits.db\")\n",
    "c = conn.cursor()\n",
    "df = pd.read_sql(\"SELECT * FROM cdm_postedits\", conn)\n",
    "conn.close()\n",
    "_unique_vals, indices = np.unique([row.system + str(row.id) for _, row in df.iterrows()], return_index=True)\n",
    "df = df.iloc[indices].sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In here we separate the system summaries by sentence and put the sentences into a list.  We will later use the Univeral Sentence Encoder to create vectors for each of the sentences.  We make sure to keep track of how many sentences each system summary has so we can perform operations on the sentences vectors for each system summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentences = []\n",
    "sentence_counts = []\n",
    "index = 0\n",
    "for _i, row in df.iterrows():\n",
    "    system_summary = row.system_summary\n",
    "    tokenized_sentences = nltk.sent_tokenize(system_summary)\n",
    "    sentence_counts.append(len(tokenized_sentences))\n",
    "    sentences.extend(tokenized_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we get the embeddings for all sentences from the Universal Sentence Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentence_embeddings = []\n",
    "with tf.Graph().as_default():\n",
    "    embed = hub.Module(\"https://tfhub.dev/google/universal-sentence-encoder-large/3\")\n",
    "    embeddings = embed(sentences)\n",
    "    tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        sess.run(tf.tables_initializer())\n",
    "        sentence_embeddings = sess.run(embeddings)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ELMo Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using /var/folders/50/y01jw_8165zgcsy6f1h8qs8m0000gn/T/tfhub_modules to cache modules.\n",
      "INFO:tensorflow:Initialize variable elmo/aggregation/scaling:0 from checkpoint b'/var/folders/50/y01jw_8165zgcsy6f1h8qs8m0000gn/T/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables' with aggregation/scaling\n",
      "INFO:tensorflow:Initialize variable elmo/aggregation/weights:0 from checkpoint b'/var/folders/50/y01jw_8165zgcsy6f1h8qs8m0000gn/T/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables' with aggregation/weights\n",
      "INFO:tensorflow:Initialize variable elmo/bilm/CNN/W_cnn_0:0 from checkpoint b'/var/folders/50/y01jw_8165zgcsy6f1h8qs8m0000gn/T/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables' with bilm/CNN/W_cnn_0\n",
      "INFO:tensorflow:Initialize variable elmo/bilm/CNN/W_cnn_1:0 from checkpoint b'/var/folders/50/y01jw_8165zgcsy6f1h8qs8m0000gn/T/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables' with bilm/CNN/W_cnn_1\n",
      "INFO:tensorflow:Initialize variable elmo/bilm/CNN/W_cnn_2:0 from checkpoint b'/var/folders/50/y01jw_8165zgcsy6f1h8qs8m0000gn/T/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables' with bilm/CNN/W_cnn_2\n",
      "INFO:tensorflow:Initialize variable elmo/bilm/CNN/W_cnn_3:0 from checkpoint b'/var/folders/50/y01jw_8165zgcsy6f1h8qs8m0000gn/T/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables' with bilm/CNN/W_cnn_3\n",
      "INFO:tensorflow:Initialize variable elmo/bilm/CNN/W_cnn_4:0 from checkpoint b'/var/folders/50/y01jw_8165zgcsy6f1h8qs8m0000gn/T/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables' with bilm/CNN/W_cnn_4\n",
      "INFO:tensorflow:Initialize variable elmo/bilm/CNN/W_cnn_5:0 from checkpoint b'/var/folders/50/y01jw_8165zgcsy6f1h8qs8m0000gn/T/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables' with bilm/CNN/W_cnn_5\n",
      "INFO:tensorflow:Initialize variable elmo/bilm/CNN/W_cnn_6:0 from checkpoint b'/var/folders/50/y01jw_8165zgcsy6f1h8qs8m0000gn/T/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables' with bilm/CNN/W_cnn_6\n",
      "INFO:tensorflow:Initialize variable elmo/bilm/CNN/b_cnn_0:0 from checkpoint b'/var/folders/50/y01jw_8165zgcsy6f1h8qs8m0000gn/T/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables' with bilm/CNN/b_cnn_0\n",
      "INFO:tensorflow:Initialize variable elmo/bilm/CNN/b_cnn_1:0 from checkpoint b'/var/folders/50/y01jw_8165zgcsy6f1h8qs8m0000gn/T/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables' with bilm/CNN/b_cnn_1\n",
      "INFO:tensorflow:Initialize variable elmo/bilm/CNN/b_cnn_2:0 from checkpoint b'/var/folders/50/y01jw_8165zgcsy6f1h8qs8m0000gn/T/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables' with bilm/CNN/b_cnn_2\n",
      "INFO:tensorflow:Initialize variable elmo/bilm/CNN/b_cnn_3:0 from checkpoint b'/var/folders/50/y01jw_8165zgcsy6f1h8qs8m0000gn/T/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables' with bilm/CNN/b_cnn_3\n",
      "INFO:tensorflow:Initialize variable elmo/bilm/CNN/b_cnn_4:0 from checkpoint b'/var/folders/50/y01jw_8165zgcsy6f1h8qs8m0000gn/T/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables' with bilm/CNN/b_cnn_4\n",
      "INFO:tensorflow:Initialize variable elmo/bilm/CNN/b_cnn_5:0 from checkpoint b'/var/folders/50/y01jw_8165zgcsy6f1h8qs8m0000gn/T/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables' with bilm/CNN/b_cnn_5\n",
      "INFO:tensorflow:Initialize variable elmo/bilm/CNN/b_cnn_6:0 from checkpoint b'/var/folders/50/y01jw_8165zgcsy6f1h8qs8m0000gn/T/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables' with bilm/CNN/b_cnn_6\n",
      "INFO:tensorflow:Initialize variable elmo/bilm/CNN_high_0/W_carry:0 from checkpoint b'/var/folders/50/y01jw_8165zgcsy6f1h8qs8m0000gn/T/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables' with bilm/CNN_high_0/W_carry\n",
      "INFO:tensorflow:Initialize variable elmo/bilm/CNN_high_0/W_transform:0 from checkpoint b'/var/folders/50/y01jw_8165zgcsy6f1h8qs8m0000gn/T/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables' with bilm/CNN_high_0/W_transform\n",
      "INFO:tensorflow:Initialize variable elmo/bilm/CNN_high_0/b_carry:0 from checkpoint b'/var/folders/50/y01jw_8165zgcsy6f1h8qs8m0000gn/T/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables' with bilm/CNN_high_0/b_carry\n",
      "INFO:tensorflow:Initialize variable elmo/bilm/CNN_high_0/b_transform:0 from checkpoint b'/var/folders/50/y01jw_8165zgcsy6f1h8qs8m0000gn/T/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables' with bilm/CNN_high_0/b_transform\n",
      "INFO:tensorflow:Initialize variable elmo/bilm/CNN_high_1/W_carry:0 from checkpoint b'/var/folders/50/y01jw_8165zgcsy6f1h8qs8m0000gn/T/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables' with bilm/CNN_high_1/W_carry\n",
      "INFO:tensorflow:Initialize variable elmo/bilm/CNN_high_1/W_transform:0 from checkpoint b'/var/folders/50/y01jw_8165zgcsy6f1h8qs8m0000gn/T/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables' with bilm/CNN_high_1/W_transform\n",
      "INFO:tensorflow:Initialize variable elmo/bilm/CNN_high_1/b_carry:0 from checkpoint b'/var/folders/50/y01jw_8165zgcsy6f1h8qs8m0000gn/T/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables' with bilm/CNN_high_1/b_carry\n",
      "INFO:tensorflow:Initialize variable elmo/bilm/CNN_high_1/b_transform:0 from checkpoint b'/var/folders/50/y01jw_8165zgcsy6f1h8qs8m0000gn/T/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables' with bilm/CNN_high_1/b_transform\n",
      "INFO:tensorflow:Initialize variable elmo/bilm/CNN_proj/W_proj:0 from checkpoint b'/var/folders/50/y01jw_8165zgcsy6f1h8qs8m0000gn/T/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables' with bilm/CNN_proj/W_proj\n",
      "INFO:tensorflow:Initialize variable elmo/bilm/CNN_proj/b_proj:0 from checkpoint b'/var/folders/50/y01jw_8165zgcsy6f1h8qs8m0000gn/T/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables' with bilm/CNN_proj/b_proj\n",
      "INFO:tensorflow:Initialize variable elmo/bilm/RNN_0/RNN/MultiRNNCell/Cell0/rnn/lstm_cell/bias:0 from checkpoint b'/var/folders/50/y01jw_8165zgcsy6f1h8qs8m0000gn/T/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables' with bilm/RNN_0/RNN/MultiRNNCell/Cell0/rnn/lstm_cell/bias\n",
      "INFO:tensorflow:Initialize variable elmo/bilm/RNN_0/RNN/MultiRNNCell/Cell0/rnn/lstm_cell/kernel:0 from checkpoint b'/var/folders/50/y01jw_8165zgcsy6f1h8qs8m0000gn/T/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables' with bilm/RNN_0/RNN/MultiRNNCell/Cell0/rnn/lstm_cell/kernel\n",
      "INFO:tensorflow:Initialize variable elmo/bilm/RNN_0/RNN/MultiRNNCell/Cell0/rnn/lstm_cell/projection/kernel:0 from checkpoint b'/var/folders/50/y01jw_8165zgcsy6f1h8qs8m0000gn/T/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables' with bilm/RNN_0/RNN/MultiRNNCell/Cell0/rnn/lstm_cell/projection/kernel\n",
      "INFO:tensorflow:Initialize variable elmo/bilm/RNN_0/RNN/MultiRNNCell/Cell1/rnn/lstm_cell/bias:0 from checkpoint b'/var/folders/50/y01jw_8165zgcsy6f1h8qs8m0000gn/T/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables' with bilm/RNN_0/RNN/MultiRNNCell/Cell1/rnn/lstm_cell/bias\n",
      "INFO:tensorflow:Initialize variable elmo/bilm/RNN_0/RNN/MultiRNNCell/Cell1/rnn/lstm_cell/kernel:0 from checkpoint b'/var/folders/50/y01jw_8165zgcsy6f1h8qs8m0000gn/T/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables' with bilm/RNN_0/RNN/MultiRNNCell/Cell1/rnn/lstm_cell/kernel\n",
      "INFO:tensorflow:Initialize variable elmo/bilm/RNN_0/RNN/MultiRNNCell/Cell1/rnn/lstm_cell/projection/kernel:0 from checkpoint b'/var/folders/50/y01jw_8165zgcsy6f1h8qs8m0000gn/T/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables' with bilm/RNN_0/RNN/MultiRNNCell/Cell1/rnn/lstm_cell/projection/kernel\n",
      "INFO:tensorflow:Initialize variable elmo/bilm/RNN_1/RNN/MultiRNNCell/Cell0/rnn/lstm_cell/bias:0 from checkpoint b'/var/folders/50/y01jw_8165zgcsy6f1h8qs8m0000gn/T/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables' with bilm/RNN_1/RNN/MultiRNNCell/Cell0/rnn/lstm_cell/bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable elmo/bilm/RNN_1/RNN/MultiRNNCell/Cell0/rnn/lstm_cell/kernel:0 from checkpoint b'/var/folders/50/y01jw_8165zgcsy6f1h8qs8m0000gn/T/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables' with bilm/RNN_1/RNN/MultiRNNCell/Cell0/rnn/lstm_cell/kernel\n",
      "INFO:tensorflow:Initialize variable elmo/bilm/RNN_1/RNN/MultiRNNCell/Cell0/rnn/lstm_cell/projection/kernel:0 from checkpoint b'/var/folders/50/y01jw_8165zgcsy6f1h8qs8m0000gn/T/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables' with bilm/RNN_1/RNN/MultiRNNCell/Cell0/rnn/lstm_cell/projection/kernel\n",
      "INFO:tensorflow:Initialize variable elmo/bilm/RNN_1/RNN/MultiRNNCell/Cell1/rnn/lstm_cell/bias:0 from checkpoint b'/var/folders/50/y01jw_8165zgcsy6f1h8qs8m0000gn/T/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables' with bilm/RNN_1/RNN/MultiRNNCell/Cell1/rnn/lstm_cell/bias\n",
      "INFO:tensorflow:Initialize variable elmo/bilm/RNN_1/RNN/MultiRNNCell/Cell1/rnn/lstm_cell/kernel:0 from checkpoint b'/var/folders/50/y01jw_8165zgcsy6f1h8qs8m0000gn/T/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables' with bilm/RNN_1/RNN/MultiRNNCell/Cell1/rnn/lstm_cell/kernel\n",
      "INFO:tensorflow:Initialize variable elmo/bilm/RNN_1/RNN/MultiRNNCell/Cell1/rnn/lstm_cell/projection/kernel:0 from checkpoint b'/var/folders/50/y01jw_8165zgcsy6f1h8qs8m0000gn/T/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables' with bilm/RNN_1/RNN/MultiRNNCell/Cell1/rnn/lstm_cell/projection/kernel\n",
      "INFO:tensorflow:Initialize variable elmo/bilm/char_embed:0 from checkpoint b'/var/folders/50/y01jw_8165zgcsy6f1h8qs8m0000gn/T/tfhub_modules/9bb74bc86f9caffc8c47dd7b33ec4bb354d9602d/variables/variables' with bilm/char_embed\n",
      "0\n",
      "200\n",
      "400\n",
      "600\n",
      "800\n",
      "1000\n",
      "1200\n",
      "1400\n",
      "1600\n",
      "1800\n",
      "2000\n",
      "2200\n",
      "2400\n",
      "2600\n",
      "2800\n",
      "3000\n",
      "3200\n",
      "3400\n",
      "3600\n",
      "3800\n",
      "4000\n",
      "4200\n",
      "4400\n",
      "4600\n",
      "4800\n",
      "5000\n",
      "5200\n",
      "5400\n",
      "5600\n",
      "5800\n",
      "6000\n",
      "6200\n",
      "6400\n",
      "6600\n",
      "6800\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 200\n",
    "elmo_batches = list(range(0, len(sentences), BATCH_SIZE))\n",
    "elmo_sentence_embeddings = []\n",
    "with tf.Graph().as_default():\n",
    "    embed = hub.Module(\"https://tfhub.dev/google/elmo/2\", name=\"elmo\")\n",
    "    tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        sess.run(tf.tables_initializer())\n",
    "        for batch_index in elmo_batches:\n",
    "            print(batch_index)\n",
    "            embeddings = embed(sentences[batch_index:batch_index+BATCH_SIZE])\n",
    "            elmo_sentence_embeddings.extend(sess.run(embeddings))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for calculating the sentence-based redundancy score. If a summary consists of only one sentence, we return 1.\n",
    "\n",
    "\n",
    "args:\n",
    "    **sentences** - the vector representations for sentences in a summary\n",
    "\n",
    "returns:\n",
    "    1 - the mean squared cosine similarity between all pairs of sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def sent_redundancy(sentences):\n",
    "    if len(sentences) == 1:\n",
    "        return 1\n",
    "    sentence_combinations = itertools.combinations(sentences, 2)\n",
    "    similarity_scores = []\n",
    "    for pair in sentence_combinations:\n",
    "        similarity_scores.append(cosine_similarity([pair[0]], [pair[1]])[0][0]**2)\n",
    "    return 1 - (sum(similarity_scores) / len(similarity_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we calculate the sent_redundancy scores for the system summaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "index = 0\n",
    "sent_redundancy_scores = []\n",
    "for count in sentence_counts:\n",
    "    system_sentence_vectors = sentence_embeddings[index:index+count]\n",
    "    sent_redundancy_scores.append(sent_redundancy(system_sentence_vectors))\n",
    "    index += count\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "index = 0\n",
    "elmo_sent_redundancy_scores = []\n",
    "for count in sentence_counts:\n",
    "    system_sentence_vectors = elmo_sentence_embeddings[index:index+count]\n",
    "    elmo_sent_redundancy_scores.append(sent_redundancy(system_sentence_vectors))\n",
    "    index += count\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df[\"elmo_redundancy\"] = elmo_sent_redundancy_scores\n",
    "df[\"use_redundandcy\"] = sent_redundancy_scores\n",
    "\n",
    "conn = sqlite3.connect('../data/cdm_postedits.db')\n",
    "c = conn.cursor()\n",
    "\n",
    "orig_df = pd.read_sql(\"SELECT * FROM cdm_postedits\", conn)\n",
    "orig_df[\"elmo_redundancy\"] = None\n",
    "orig_df[\"use_redundancy\"] = None\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    orig_df.loc[(orig_df.id == row.id) & (orig_df.system == row.system), \"elmo_redundancy\"] = row.elmo_redundancy\n",
    "    orig_df.loc[(orig_df.id == row.id) & (orig_df.system == row.system), \"use_redundancy\"] = row.use_redundandcy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Putting scores in .db file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c.execute('DROP TABLE IF EXISTS cdm_postedits;')\n",
    "rows = orig_df.values.tolist()\n",
    "\n",
    "# Create table\n",
    "c.execute('''CREATE TABLE cdm_postedits\n",
    "             (annotator_id integer, edit text, grammar integer, hter integer, id integer, overall integer, redundancy integer, reference text, sim real, system text, system_summary text, elmo_redundancy real, use_redundancy real)''')\n",
    "\n",
    "# Insert a row of data\n",
    "c.executemany('INSERT INTO cdm_postedits VALUES (?,?,?,?,?,?,?,?,?,?,?,?,?)', rows)\n",
    "\n",
    "# Save (commit) the changes\n",
    "conn.commit()\n",
    "\n",
    "\n",
    "conn.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
